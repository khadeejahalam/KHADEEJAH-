#Word Enumeration:
from mrjob.job import MRJob
import re

class WordEnumerationMR(MRJob):
    def mapper(self, _, line):
        words = re.findall(r'\b\w+\b', line.lower())
        for word in words:
            yield word, 1

    def reducer(self, word, counts):
        yield word, sum(counts)

if __name__ == '__main__':
    WordEnumerationMR.run()
#Document Count:
from mrjob.job import MRJob
import re

class DocumentCountMR(MRJob):
    def mapper(self, _, line):
        words = re.findall(r'\b\w+\b', line.lower())
        for word in set(words):
            yield word, 1

    def reducer(self, word, counts):
        yield word, sum(counts)

if __name__ == '__main__':
    DocumentCountMR.run()
#Indexer:
from mrjob.job import MRJob
import re

class IndexerMR(MRJob):
    def mapper(self, _, line):
        doc_id, text = line.split(',', 1)
        words = re.findall(r'\b\w+\b', text.lower())
        word_counts = {}
        total_words = len(words)
        for word in words:
            word_counts[word] = word_counts.get(word, 0) + 1

        for word, count in word_counts.items():
            tf = count / total_words
            yield word, (doc_id, tf)

    def reducer(self, word, doc_tfs):
        yield word, list(doc_tfs)

if __name__ == '__main__':
    IndexerMR.run()
#Driver Program:
from WordEnumerationMR import WordEnumerationMR
from DocumentCountMR import DocumentCountMR
from IndexerMR import IndexerMR

def run_word_enumeration(input_path, output_path):
    mr_job = WordEnumerationMR(args=[input_path, '-r', 'hadoop', '--output-dir', output_path])
    with mr_job.make_runner() as runner:
        runner.run()

def run_document_count(input_path, output_path):
    mr_job = DocumentCountMR(args=[input_path, '-r', 'hadoop', '--output-dir', output_path])
    with mr_job.make_runner() as runner:
        runner.run()

def run_indexer(input_path, output_path):
    mr_job = IndexerMR(args=[input_path, '-r', 'hadoop', '--output-dir', output_path])
    with mr_job.make_runner() as runner:
        runner.run()

if __name__ == '__main__':
    input_path = '/path/to/input_file'
    word_enum_output_path = '/path/to/word_enum_output'
    doc_count_output_path = '/path/to/doc_count_output'
    indexer_output_path = '/path/to/indexer_output'

    run_word_enumeration(input_path, word_enum_output_path)
    run_document_count(input_path, doc_count_output_path)
    run_indexer(input_path, indexer_output_path)
